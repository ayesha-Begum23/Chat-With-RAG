{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arshiya-Begum30/Chat-with-RAG/blob/main/RAG_Model_for_QA_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzk188wxCbKd",
        "outputId": "dad194bc-f4a6-48a0-821c-9702633622bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-5.1.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.5)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.0.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.3)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-5.1.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.5/245.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-interface, h11, pinecone-plugin-inference, httpcore, pinecone, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 pinecone-5.1.0 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "XWnwxSIrZT8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual API keys\n",
        "GROQ_API_KEY=\"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\"\n",
        "PINECONE_API_KEY=\"150f3e68-2780-4930-a79c-4da2def2f052\""
      ],
      "metadata": {
        "id": "C7-DHPiHYdb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Pinecone client\n",
        "pc = pinecone.Pinecone(api_key=api_key_pinecone)\n",
        "index_name = \"qa-bot-index\"\n",
        "\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,  # Ensure this matches your embedding dimension\n",
        "        metric=\"euclidean\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "I-wW8PQ0TDdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Upsert vectors into the index\n",
        "index.upsert(\n",
        "    vectors=[\n",
        "        {\"id\": \"vec1\", \"values\": [0.1]*1536, \"metadata\": {\"text\": \"Document 1: Information about topic A.\"}},\n",
        "        {\"id\": \"vec2\", \"values\": [0.2]*1536, \"metadata\": {\"text\": \"Document 2: Details on subject B.\"}},\n",
        "        {\"id\": \"vec3\", \"values\": [0.3]*1536, \"metadata\": {\"text\": \"Document 3: Insights on topic A.\"}},\n",
        "        {\"id\": \"vec4\", \"values\": [0.4]*1536, \"metadata\": {\"text\": \"Document 4: Analysis of subject C.\"}}\n",
        "    ],\n",
        "    namespace=\"ns1\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ScHc0RyTDi9",
        "outputId": "4a21cd0e-cf58-4e62-8e43-71da10f15443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=api_key_groq)\n",
        "\n",
        "# Function to encode queries to vectors (Placeholder implementation)\n",
        "def encode_query_to_vector(query):\n",
        "    # Implement your vector encoding logic here\n",
        "    # This is a placeholder that should be replaced with actual encoding\n",
        "    return [0.3]*1536"
      ],
      "metadata": {
        "id": "CEP7ErbDTDmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to retrieve relevant documents from Pinecone\n",
        "def retrieve_documents(query, top_k=5):\n",
        "    query_vector = encode_query_to_vector(query)  # Implement the actual encoding function\n",
        "    results = index.query(\n",
        "        namespace=\"ns1\",\n",
        "        vector=query_vector,\n",
        "        top_k=top_k,\n",
        "        include_values=True,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    retrieved_docs = [match['metadata']['text'] for match in results['matches']]\n",
        "    return retrieved_docs"
      ],
      "metadata": {
        "id": "UKhX0ROiTQG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to perform RAG-based chat completion using Groq\n",
        "def get_rag_chat_completion(prompt):\n",
        "    try:\n",
        "        # Retrieve relevant documents based on the prompt\n",
        "        retrieved_docs = retrieve_documents(prompt)\n",
        "\n",
        "        # Combine the prompt with the retrieved documents\n",
        "        combined_prompt = prompt + \"\\n\\n\" + \"\\n\".join(retrieved_docs)\n",
        "\n",
        "        # Perform a chat completion with Groq\n",
        "        chat_completion = groq_client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": combined_prompt\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama3-8b-8192\"  # Replace with the model you want to use\n",
        "        )\n",
        "        # Return the response content\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    prompt = \"Explain the significance of topic A.\"\n",
        "    response = get_rag_chat_completion(prompt)\n",
        "    print(\"Response from Groq:\", response)"
      ],
      "metadata": {
        "id": "IgKp7weraCJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5846ce35-989b-4454-cacf-366d09c35143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Groq: A clever arrangement!\n",
            "\n",
            "It seems that \"topic A\" is a recurring theme throughout these documents. Here's a possible interpretation:\n",
            "\n",
            "* Document 1: This is a foundational text that provides an overview of topic A, introducing the reader to its significance and importance.\n",
            "* Document 2: This text provides more details about a related subject B, which might be a subtopic or a specific aspect of topic A.\n",
            "* Document 3: This document delves deeper into topic A, offering insights and analysis that build upon the information provided in Document 1.\n",
            "* Document 4: This text examines a separate subject C, which might be connected to topic A or provide a contrasting perspective.\n",
            "\n",
            "The significance of topic A lies in its recurring presence across these documents. It likely represents a core concept, idea, or theme that is central to the overall narrative or discussion. By focusing on topic A, the reader can gain a deeper understanding of the larger context and the connections between the various ideas presented in the documents.\n",
            "\n",
            "In essence, topic A serves as a thread that weaves together the diverse information from Documents 1 to 4, allowing the reader to build a comprehensive understanding of the subject matter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4MOMsDSZTdXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}